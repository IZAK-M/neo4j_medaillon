import pandas as pd
import numpy as np
from pathlib import Path

import sys

# Ajoute le dossier racine au chemin d'import
BASE_DIR = Path(__file__).resolve().parent.parent
sys.path.append(str(BASE_DIR))

from quality.gx_checkpoint import validate_graph_quality

# Chemins
BASE_DIR = Path(__file__).resolve().parent.parent
BRONZE_DIR = BASE_DIR / "data" / "bronze"
SILVER_DIR = BASE_DIR / "data" / "silver"
NUM_SHARDS = 8

# Chargement des donn√©es
edges_df = pd.read_parquet(BRONZE_DIR / "edges.parquet")
nodes_df = pd.read_parquet(BRONZE_DIR / "nodes.parquet")

# Validation
results = validate_graph_quality(nodes_df, edges_df)

# V√©rification des r√©sultats
if not all(r["success"] for r in results.values()):
    print("‚ùå Donn√©es invalides, nettoyage en cours...")
    edges_df = edges_df.dropna(subset=["src", "dst"])
    nodes_df = nodes_df.drop_duplicates(subset=["id"])
    nodes_df = nodes_df.dropna()
    print("‚úÖ Donn√©es valides, partitionnement en cours...")
    print("üìÇ Partitionnement : ")
else:
    print("‚úÖ Donn√©es valides, partitionnement en cours...")
    print("üìÇ Partitionnement : ")

# Cr√©ation d'une copie explicite pour √©viter le warning ou un comportement inattendus
edges_df = edges_df.copy()

# Attribution al√©atoire d'un shard √† chaque edge
edges_df["shard"] = np.random.randint(0, NUM_SHARDS, size=len(edges_df))

# √âcritures des nodes
SILVER_DIR.mkdir(parents=True, exist_ok=True)
nodes_df.to_parquet(SILVER_DIR / "nodes.parquet", compression="snappy")

# Partitionnement et √©criture
for shard_id in range(NUM_SHARDS):
    shard_dir = SILVER_DIR / f"shard={shard_id}"
    shard_dir.mkdir(parents=True, exist_ok=True)

    # √âcriture des edges
    shard_edges = edges_df[edges_df["shard"] == shard_id].drop(columns=["shard"])
    shard_edges.to_parquet(shard_dir / "edges.parquet", compression="snappy")

    print(f"‚úÖ Shard {shard_id} ‚Üí {len(shard_edges)} edges")